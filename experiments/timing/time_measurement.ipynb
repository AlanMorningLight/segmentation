{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jr0th/github/segmentation/code/')\n",
    "import helper.model_builder\n",
    "import helper.metrics\n",
    "\n",
    "import skimage.io\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import keras\n",
    "\n",
    "# build session running on a specific GPU\n",
    "configuration = tf.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"2\"\n",
    "session = tf.Session(config = configuration)\n",
    "\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_load_pattern = '/home/jr0th/github/segmentation/data/BBBC022_hand_200/test/x/all/*.png'\n",
    "\n",
    "# uncomment the following line to use full images instead of crops\n",
    "img_load_pattern = '/home/jr0th/github/segmentation/data/BBBC022_hand_200/test/x_big/*.png'\n",
    "\n",
    "# use latest checkpoint\n",
    "weights_path = '/home/jr0th/github/segmentation/checkpoints/checkpoint_boundary_4_generator.hdf5'\n",
    "\n",
    "# get images\n",
    "images = skimage.io.imread_collection(img_load_pattern).concatenate()\n",
    "\n",
    "# assume that images are all the same shape\n",
    "n_images = images.shape[0]\n",
    "dim1 = images.shape[1]\n",
    "dim2 = images.shape[2]\n",
    "\n",
    "# build model and load weights\n",
    "model = helper.model_builder.get_model_1_class(dim1, dim2)\n",
    "\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST INFERENCE AND POST PROCESSING TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# label = 'PATCH'\n",
    "# label = 'PATCH_thresh'\n",
    "# label = 'PATCH_remove_small'\n",
    "# label = 'PATCH_thresh_remove_small'\n",
    "\n",
    "# label = 'FULL'\n",
    "# label = 'FULL_thresh'\n",
    "# label = 'FULL_remove_small'\n",
    "label = 'FULL_thresh_remove_small'\n",
    "\n",
    "N = 100\n",
    "\n",
    "time_inf = np.zeros(N)\n",
    "time_pp = np.zeros(N)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "print('Heating up GPU now.')\n",
    "\n",
    "# heat up GPU\n",
    "for i in range(10):\n",
    "    model.predict(np.zeros((batch_size, dim1, dim2, 1)), batch_size=batch_size)\n",
    "\n",
    "print('GPU is hot now.')\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    print('Iteration', i+1, 'of', N)\n",
    "    \n",
    "    # get random image\n",
    "    img = images[np.random.randint(0, n_images)]\n",
    "\n",
    "    # preprocessing\n",
    "    img_rescaled = np.reshape(img / 255, (-1, dim1, dim2, 1))\n",
    "\n",
    "    # inference\n",
    "    start_inf = time.time()\n",
    "    outline_pred = model.predict(img_rescaled)\n",
    "    end_inf = time.time()\n",
    "\n",
    "    time_inf[i] = end_inf - start_inf\n",
    "\n",
    "    # postprocessing\n",
    "    outline_pred = outline_pred.squeeze()\n",
    "    start_pp = time.time()\n",
    "    contour = helper.metrics.probmap_to_contour(outline_pred)\n",
    "    segmentation = helper.metrics.contour_to_label(contour, img_rescaled)\n",
    "    end_pp = time.time()\n",
    "\n",
    "    time_pp[i] = end_pp - start_pp\n",
    "    \n",
    "    # visualize\n",
    "    visualize = False\n",
    "    if(visualize):\n",
    "        plt.imshow(img)\n",
    "        plt.colorbar()\n",
    "        plt.title('Image')\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(outline_pred)\n",
    "        plt.colorbar()\n",
    "        plt.title('Outline Probability Map')\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(contour)\n",
    "        plt.colorbar()\n",
    "        plt.title('Thresholded Contours')\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(segmentation)\n",
    "        plt.colorbar()\n",
    "        plt.title('Predicted Segmentation')\n",
    "        plt.show()\n",
    "\n",
    "plt.boxplot([time_inf[1:], time_pp[1:]], labels=['Forward Pass', 'Post Processing'])\n",
    "plt.title('Running Time')\n",
    "plt.ylabel('time in seconds')\n",
    "plt.savefig('inf_pp_time_' + label + '.svg', format='svg')\n",
    "\n",
    "np.save('inf_pp_time_' + label + '.npy',[time_inf, time_pp])\n",
    "\n",
    "print('Mean time for inference: ', np.mean(time_inf))\n",
    "print('Mean time for inference: ', np.mean(time_pp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DEPENDENCY ON BATCH SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_images = 15\n",
    "batch_size = 5\n",
    "\n",
    "N = 100\n",
    "\n",
    "runtimes_per_image = np.zeros((N, max_n_images))\n",
    "\n",
    "print('Heating up GPU now.')\n",
    "\n",
    "# heat up GPU\n",
    "for i in range(10):\n",
    "    model.predict(np.zeros((batch_size, dim1, dim2, 1)), batch_size=batch_size)\n",
    "\n",
    "print('GPU is hot now.')\n",
    "\n",
    "# loop over iterations\n",
    "for i in range(N):\n",
    "    \n",
    "    # loop over number of images\n",
    "    for n_images in range(1, max_n_images + 1):\n",
    "\n",
    "        # prepare data\n",
    "        data = np.zeros((n_images, dim1, dim2, 1))\n",
    "        for j in range(n_images):\n",
    "            # get random image\n",
    "            data[j,:,:,0] = images[j]\n",
    "\n",
    "        # preprocessing\n",
    "        data = data / 255\n",
    "\n",
    "        # inference\n",
    "        time_inf = 0\n",
    "        start_inf = time.time()\n",
    "        outline_pred = model.predict(data, batch_size=batch_size)\n",
    "        end_inf = time.time()\n",
    "\n",
    "        time_inf = end_inf - start_inf\n",
    "\n",
    "        # visualize\n",
    "        visualize = False\n",
    "        if(visualize):\n",
    "            plt.imshow(outline_pred[0].squeeze())\n",
    "            plt.show()\n",
    "\n",
    "        runtimes_per_image[i,n_images-1] = time_inf / n_images\n",
    "        print('Time for inference per image:', np.round(runtimes_per_image[i, n_images-1], decimals=2), 'with', n_images, 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(runtimes_per_image[1:])\n",
    "plt.title('Running Time')\n",
    "plt.ylabel('inference time per image in seconds')\n",
    "plt.xlabel('data set size (batch size = '+str(batch_size)+')')\n",
    "plt.savefig('runtime_batch_size.svg', format='svg')\n",
    "\n",
    "np.save('runtimes_per_image.npy', runtimes_per_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER TO GET MEAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('./inf_pp_time_PATCH_thresh_remove_small.npy')\n",
    "np.mean(data[:,1:], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
